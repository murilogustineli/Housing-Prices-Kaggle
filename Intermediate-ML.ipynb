{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "018bfe26-0c4e-4b80-bbb9-7eadd9be40ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Kaggle: Intermediate Machine Learning\n",
    "### Introduction\n",
    "Load the training and validation features in `X_train` and `X_valid`, along with the prediction targets in `y_train` and `y_valid`.  The test features are loaded in `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70477f86-f45e-4d0c-b0cb-b7fa0d5fd9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adc4d7ad-16f2-49fe-b5fa-0ab3148c61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "X_full = pd.read_csv('../Intro-to-ML/home-data-for-ml-course/train.csv', index_col='Id')\n",
    "X_test_full = pd.read_csv('../Intro-to-ML/home-data-for-ml-course/test.csv', index_col='Id')\n",
    "\n",
    "# Obtain target and features\n",
    "y = X_full.SalePrice\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = X_full[features].copy()\n",
    "X_test = X_test_full[features].copy()\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "191e51bf-bf79-41b5-a84f-f9b2be027f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>11694</td>\n",
       "      <td>2007</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>6600</td>\n",
       "      <td>1962</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>13360</td>\n",
       "      <td>1921</td>\n",
       "      <td>964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>13265</td>\n",
       "      <td>2002</td>\n",
       "      <td>1689</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>13704</td>\n",
       "      <td>2001</td>\n",
       "      <td>1541</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
       "Id                                                                    \n",
       "619    11694       2007      1828         0         2             3   \n",
       "871     6600       1962       894         0         1             2   \n",
       "93     13360       1921       964         0         1             2   \n",
       "818    13265       2002      1689         0         2             3   \n",
       "303    13704       2001      1541         0         2             3   \n",
       "\n",
       "     TotRmsAbvGrd  \n",
       "Id                 \n",
       "619             9  \n",
       "871             5  \n",
       "93              5  \n",
       "818             7  \n",
       "303             6  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at first few rows of data for the train set\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47568a-190b-41eb-9a03-9197d695c67d",
   "metadata": {},
   "source": [
    "Defining five different Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71486f89-aa15-43a8-9dae-9fc931a7b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "model_1 = RandomForestRegressor(n_estimators=50, random_state=0)\n",
    "model_2 = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_3 = RandomForestRegressor(n_estimators=100, criterion='absolute_error', random_state=0)\n",
    "model_4 = RandomForestRegressor(n_estimators=200, min_samples_split=20, random_state=0)\n",
    "model_5 = RandomForestRegressor(n_estimators=100, max_depth=7, random_state=0)\n",
    "\n",
    "models = [model_1, model_2, model_3, model_4, model_5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c553416-d621-415d-840a-732d2f3dfd50",
   "metadata": {},
   "source": [
    "To select the best model out of the five, we define a function `score_model()` below.  This function returns the mean absolute error (MAE) from the validation set.  Recall that the best model will obtain the lowest MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ed4001-efd3-4783-961d-e7a662e06585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 \t MAE: 24015.492818003917\n",
      "Model 2 \t MAE: 23740.979228636657\n",
      "Model 3 \t MAE: 23528.78421232877\n",
      "Model 4 \t MAE: 23996.676789668687\n",
      "Model 5 \t MAE: 23706.672864217904\n"
     ]
    }
   ],
   "source": [
    "# Function for comparing different models\n",
    "def score_model(model, X_t=X_train, X_v=X_valid, y_t=y_train, y_v=y_valid):\n",
    "    model.fit(X_t, y_t)\n",
    "    preds = model.predict(X_v)\n",
    "    return mean_absolute_error(y_v, preds)\n",
    "\n",
    "model_runs = {}\n",
    "for i in range(len(models)):\n",
    "    mae = score_model(models[i])\n",
    "    model_runs[f'model_{i+1}'] = [mae, models[i]]\n",
    "    print(f\"Model {i+1} \\t MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf61ad-0ee0-4fea-9c67-526b8f11b29f",
   "metadata": {},
   "source": [
    "### Evaluate and select best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b67b879-796c-43e0-a804-dcb6400c969f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[23528.78421232877,\n",
       " RandomForestRegressor(criterion='absolute_error', random_state=0)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = min(model_runs.values())\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541d0fc5-b6e7-4d43-a8ae-6b4119868d13",
   "metadata": {},
   "source": [
    "### Generate test predictions\n",
    "Create a Random Forest model with the variable name `my_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1f32883-4d79-4e33-a7ef-ef4300e43dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(criterion='absolute_error', random_state=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Random Forest model from best_model\n",
    "my_model = best_model[1]\n",
    "my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30edcdac-ea0b-420b-bd2f-6f505822cf96",
   "metadata": {},
   "source": [
    "Fit the model to the training and validation sets, and generate predictions on the test set saved as `X_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bcfbace-b2ab-4273-839b-f4169fef5ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model to the training set\n",
    "my_model.fit(X, y)\n",
    "\n",
    "# Generate predictions\n",
    "preds_test = my_model.predict(X_test)\n",
    "\n",
    "# Save predictions in the format used for competition scoring\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice:': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38669ec6-1bd9-4b2b-8832-a3ab2b63e124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice:</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>119433.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>158367.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>185351.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>178343.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>192898.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>86155.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>89050.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>156296.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>132232.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>230870.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  SalePrice:\n",
       "0     1461   119433.08\n",
       "1     1462   158367.50\n",
       "2     1463   185351.21\n",
       "3     1464   178343.12\n",
       "4     1465   192898.29\n",
       "...    ...         ...\n",
       "1454  2915    86155.00\n",
       "1455  2916    89050.00\n",
       "1456  2917   156296.92\n",
       "1457  2918   132232.50\n",
       "1458  2919   230870.60\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317fab11-67d9-4e10-8942-1524de6be5cc",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe24ff-aac8-4718-9217-5aa5ee46eb86",
   "metadata": {},
   "source": [
    "There are many ways data can end up with missing values. For example,\n",
    "- A 2 bedroom house won't include a value for the size of a third bedroom.\n",
    "- A survey respondent may choose not to share his income.\n",
    "\n",
    "Most machine learning libraries (including scikit-learn) give an error if you try to build a model using data with missing values. So we need methods to deal with missing values before building the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7419f523-d966-4383-a1a3-64323710d983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep things simple, we'll use only numerical predictors\n",
    "X = X_full.select_dtypes(exclude=['object'])\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "X_test = X_test_full.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "458b1af0-0fad-4f22-8ef2-546bd37e5ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1168, 36)\n",
      "LotFrontage    212\n",
      "MasVnrArea       6\n",
      "GarageYrBlt     58\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74a20699-f01e-4023-9ef0-eab7c6f8de5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotFrontage', 'MasVnrArea', 'GarageYrBlt']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "cols_with_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23c4441c-e86d-471c-a73c-474ec2d7a3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1168\n",
      "3\n",
      "276\n"
     ]
    }
   ],
   "source": [
    "# Fill in the line below: How many rows are in the training data?\n",
    "num_rows = X_train.shape[0]\n",
    "print(num_rows)\n",
    "\n",
    "# Fill in the line below: How many columns in the training data\n",
    "# have missing values?\n",
    "num_cols_with_missing = len([col for col in X_train.columns if X_train[col].isnull().any()])\n",
    "print(num_cols_with_missing)\n",
    "\n",
    "# Fill in the line below: How many missing entries are contained in \n",
    "# all of the training data?\n",
    "tot_missing = sum(X_train.isnull().sum())\n",
    "print(tot_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c43982-baba-40bf-b87c-606580125a2a",
   "metadata": {},
   "source": [
    "To compare different approaches to dealing with missing values, you'll use the same `score_dataset()` function from the tutorial.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9f03047-2f3e-410d-ba34-94724538c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4bf13-7345-4bdd-883a-8fa63f604c18",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Approach 1: Drop columns with missing values\n",
    "Preprocess the data in `X_train` and `X_valid` to remove columns with missing values.  Set the preprocessed DataFrames to `reduced_X_train` and `reduced_X_valid`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736cfb3f-d1b0-4b59-9a78-e71a694e2ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "\n",
    "# Fill in the lines below: drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n",
    "# Check your answers\n",
    "missing_vals = (reduced_X_train.isnull().sum())\n",
    "print(missing_vals[missing_vals > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83a131-1c97-4566-8137-7fa0e2e33e3f",
   "metadata": {},
   "source": [
    "Get MAE for this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b734749-9070-42e2-b800-5568dfa62759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Drop columns with missing values): 17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Drop columns with missing values):\",\n",
    "      score_dataset(X_train=reduced_X_train, X_valid=reduced_X_valid, y_train=y_train, y_valid=y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f2d2fa-8df3-4005-85c5-b14e183c4584",
   "metadata": {},
   "source": [
    "### Approach 2: Imputation\n",
    "Impute missing values with the mean value along each column.  Set the preprocessed DataFrames to `imputed_X_train` and `imputed_X_valid`.  Make sure that the column names match those in `X_train` and `X_valid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4644fa22-a283-429a-af7c-3691028185a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the lines below: imputation\n",
    "imputer = SimpleImputer() # Your code here\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(imputer.transform(X_valid))\n",
    "\n",
    "# Fill in the lines below: imputation removed column names; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d529f59-422f-45b1-924b-06882247d97d",
   "metadata": {},
   "source": [
    "Get MAE for this approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12693eab-91a4-4680-9a02-6284384629d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Imputation): 18062.894611872147\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE (Imputation):\",\n",
    "      score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6496eb8c-92b1-4b54-9fe7-3fe141ead717",
   "metadata": {},
   "source": [
    "### Categorical Variables\n",
    "There's a lot of non-numeric data out there. Here's how to use it for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3cee018-d891-4191-bdcf-f219a2276344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "X = pd.read_csv('../Intro-to-ML/home-data-for-ml-course/train.csv', index_col='Id')\n",
    "X_test = pd.read_csv('../Intro-to-ML/home-data-for-ml-course/test.csv', index_col='Id')\n",
    "\n",
    "# Remove rows with missing target, separarte target from features\n",
    "X.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X['SalePrice']\n",
    "X.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# To keep things simple, we'll drop the columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()]\n",
    "X.drop(cols_with_missing, axis=1, inplace=True)\n",
    "X_test.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "# Train/Validation split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6814036-29f4-4686-a439-8aaa6b7d178e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>11694</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2007</td>\n",
       "      <td>New</td>\n",
       "      <td>Partial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>6600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NAmes</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>13360</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13265</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Mitchel</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>13704</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSSubClass MSZoning  LotArea Street LotShape LandContour Utilities  \\\n",
       "Id                                                                        \n",
       "619          20       RL    11694   Pave      Reg         Lvl    AllPub   \n",
       "871          20       RL     6600   Pave      Reg         Lvl    AllPub   \n",
       "93           30       RL    13360   Pave      IR1         HLS    AllPub   \n",
       "818          20       RL    13265   Pave      IR1         Lvl    AllPub   \n",
       "303          20       RL    13704   Pave      IR1         Lvl    AllPub   \n",
       "\n",
       "    LotConfig LandSlope Neighborhood  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "Id                                    ...                                       \n",
       "619    Inside       Gtl      NridgHt  ...         108             0         0   \n",
       "871    Inside       Gtl        NAmes  ...           0             0         0   \n",
       "93     Inside       Gtl      Crawfor  ...           0            44         0   \n",
       "818   CulDSac       Gtl      Mitchel  ...          59             0         0   \n",
       "303    Corner       Gtl      CollgCr  ...          81             0         0   \n",
       "\n",
       "    ScreenPorch  PoolArea  MiscVal  MoSold  YrSold SaleType SaleCondition  \n",
       "Id                                                                         \n",
       "619         260         0        0       7    2007      New       Partial  \n",
       "871           0         0        0       8    2009       WD        Normal  \n",
       "93            0         0        0       8    2009       WD        Normal  \n",
       "818           0         0        0       7    2008       WD        Normal  \n",
       "303           0         0        0       1    2006       WD        Normal  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc58184f-4ccf-41a4-ae64-f48c61cc6a33",
   "metadata": {},
   "source": [
    "To compare different models, I'll use the same `score_dataset()` function.  This function reports the [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) (MAE) from a random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa518315-e92e-4e53-ae52-fe4a107935e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare different Random Forest models\n",
    "def score_model(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ff5c1-6d6c-4d9c-b134-217329a7175b",
   "metadata": {},
   "source": [
    "### Approach 1: Drop columns with categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e5122e5-3611-4c48-9b66-a843a9ecaa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with categorical data\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Drop columns\n",
    "drop_X_train = X_train.drop(categorical_cols, axis=1)\n",
    "drop_X_valid = X_valid.drop(categorical_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b1737e1-2c93-47db-8a5c-99741e9cfa9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Drop categorical variables): 17837.82570776256\n"
     ]
    }
   ],
   "source": [
    "# Get MAE for this approach\n",
    "print('MAE (Drop categorical variables):',\n",
    "      score_model(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb638d-8834-459e-9241-e37b2fa5e407",
   "metadata": {},
   "source": [
    "Before jumping into ordinal encoding, we'll investigate the dataset.  Specifically, we'll look at the `'Condition2'` column.  The code cell below prints the unique entries in both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "506243e7-c58b-4968-87ad-266c4958ae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'Condition2' column in training data: ['Norm' 'PosA' 'Feedr' 'PosN' 'Artery' 'RRAe']\n",
      "\n",
      "Unique values in 'Condition2' column in validation data: ['Norm' 'RRAn' 'RRNn' 'Artery' 'Feedr' 'PosN']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in 'Condition2' column in training data:\", X_train['Condition2'].unique())\n",
    "print(\"\\nUnique values in 'Condition2' column in validation data:\", X_valid['Condition2'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de90c2-6410-4004-9880-31405f92a5a2",
   "metadata": {},
   "source": [
    "### Approach 2: Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c275a260-4921-4bce-9475-5d829bfa3130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be ordinal encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped: ['RoofMatl', 'Functional', 'Condition2']\n"
     ]
    }
   ],
   "source": [
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "\n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols) - set(good_label_cols))\n",
    "\n",
    "print(\"Categorical columns that will be ordinal encoded:\", good_label_cols)\n",
    "print(\"\\nCategorical columns that will be dropped:\", bad_label_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737576f-cdac-4fa2-bb0f-ccb9dae917e5",
   "metadata": {},
   "source": [
    "Ordinal encode the data in `X_train` and `X_valid`.  Set the preprocessed DataFrames to `label_X_train` and `label_X_valid`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20929351-d7ac-418c-aa64-71c8afa27b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop categorical columns that will not be encoded\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Apply ordinal encoder \n",
    "ordinal_encoder = OrdinalEncoder() # Your code here\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "795a4bdc-384f-49b6-b38f-231657143bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>...</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSZoning  Street  LotShape  LandContour  Utilities  LotConfig  LandSlope  \\\n",
       "Id                                                                              \n",
       "619       3.0     1.0       3.0          3.0        0.0        4.0        0.0   \n",
       "871       3.0     1.0       3.0          3.0        0.0        4.0        0.0   \n",
       "93        3.0     1.0       0.0          1.0        0.0        4.0        0.0   \n",
       "818       3.0     1.0       0.0          3.0        0.0        1.0        0.0   \n",
       "303       3.0     1.0       0.0          3.0        0.0        0.0        0.0   \n",
       "\n",
       "     Neighborhood  Condition1  BldgType  ...  ExterQual  ExterCond  \\\n",
       "Id                                       ...                         \n",
       "619          16.0         2.0       0.0  ...        0.0        4.0   \n",
       "871          12.0         4.0       0.0  ...        3.0        4.0   \n",
       "93            6.0         2.0       0.0  ...        3.0        2.0   \n",
       "818          11.0         2.0       0.0  ...        2.0        4.0   \n",
       "303           5.0         2.0       0.0  ...        2.0        4.0   \n",
       "\n",
       "     Foundation  Heating  HeatingQC  CentralAir  KitchenQual  PavedDrive  \\\n",
       "Id                                                                         \n",
       "619         2.0      1.0        0.0         1.0          2.0         2.0   \n",
       "871         1.0      1.0        2.0         0.0          3.0         2.0   \n",
       "93          0.0      1.0        0.0         1.0          3.0         2.0   \n",
       "818         2.0      1.0        0.0         1.0          2.0         2.0   \n",
       "303         2.0      1.0        0.0         1.0          2.0         2.0   \n",
       "\n",
       "     SaleType  SaleCondition  \n",
       "Id                            \n",
       "619       6.0            5.0  \n",
       "871       8.0            4.0  \n",
       "93        8.0            4.0  \n",
       "818       8.0            4.0  \n",
       "303       8.0            4.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_X_train[good_label_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd64d2b4-4424-481a-b9b1-0d312b60d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Ordinal Encoder): 17098.01649543379\n"
     ]
    }
   ],
   "source": [
    "print('MAE (Ordinal Encoder):',\n",
    "      score_model(label_X_train, label_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcbb35da-f7c7-467a-a051-a2e5fca0afe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Street', 2),\n",
       " ('Utilities', 2),\n",
       " ('CentralAir', 2),\n",
       " ('LandSlope', 3),\n",
       " ('PavedDrive', 3),\n",
       " ('LotShape', 4),\n",
       " ('LandContour', 4),\n",
       " ('ExterQual', 4),\n",
       " ('KitchenQual', 4),\n",
       " ('MSZoning', 5),\n",
       " ('LotConfig', 5),\n",
       " ('BldgType', 5),\n",
       " ('ExterCond', 5),\n",
       " ('HeatingQC', 5),\n",
       " ('Condition2', 6),\n",
       " ('RoofStyle', 6),\n",
       " ('Foundation', 6),\n",
       " ('Heating', 6),\n",
       " ('Functional', 6),\n",
       " ('SaleCondition', 6),\n",
       " ('RoofMatl', 7),\n",
       " ('HouseStyle', 8),\n",
       " ('Condition1', 9),\n",
       " ('SaleType', 9),\n",
       " ('Exterior1st', 15),\n",
       " ('Exterior2nd', 16),\n",
       " ('Neighborhood', 25)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get number of unique entries in each column with categorical data\n",
    "object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "d = dict(zip(object_cols, object_nunique))\n",
    "\n",
    "# Print number of unique entries by column, in ascending order\n",
    "sorted(d.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3991284-57c3-4b58-bfed-847a9ab1d213",
   "metadata": {},
   "source": [
    "### Investigate Cardinality\n",
    "The output above shows, for each column with categorical data, the number of unique values in the column.  For instance, the `'Street'` column in the training data has two unique values: `'Grvl'` and `'Pave'`, corresponding to a gravel road and a paved road, respectively.\n",
    "\n",
    "We refer to the number of unique entries of a categorical variable as the **cardinality** of that categorical variable.  For instance, the `'Street'` variable has cardinality 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc4b557c-c772-41a8-a794-385c1ece73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neighborhood', 'Exterior1st', 'Exterior2nd']\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "# Columns with cardinality greater than 10\n",
    "high_cardinality_cols = [k for k,v in d.items() if v > 10]\n",
    "print(high_cardinality_cols)\n",
    "\n",
    "# How many columns are needed to one-hot encode the 'Neighborhood' variable in the training data?\n",
    "num_cols_neighborhood = d['Neighborhood']\n",
    "print(num_cols_neighborhood)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c868f8d1-15f4-49ee-adb5-0a6eaddee0cb",
   "metadata": {},
   "source": [
    "Let's use **one-hot encoding**. \n",
    "\n",
    "But, instead of encoding all of the categorical variables in the dataset, you'll only create a one-hot encoding for columns with cardinality less than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "712c8fb3-7714-4615-aa2d-11aacf995ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleType', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior1st', 'Neighborhood', 'Exterior2nd']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(object_cols) - set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2f829ca-2e7f-4c14-832f-57226ea74a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use as many lines of code as you need!\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[low_cardinality_cols]))\n",
    "\n",
    "# One-Hot encoding removed index; put it back\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index \n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "affc3b5b-02b6-4411-a36c-5de20dc097f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgustine\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (One-Hot Encoding): 17525.345719178084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgustine\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print('MAE (One-Hot Encoding):',\n",
    "      score_model(OH_X_train, OH_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90bd2e2-4a4d-48fa-8946-df2715a0aea1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Submit results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12f0a0ab-cc96-45d0-b022-ce0d09f5a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path, target):\n",
    "    \"\"\"\n",
    "    Function that does the following:\n",
    "    1. Loads the train and test datasets\n",
    "    2. Remove rows with missing target and separarte target from features\n",
    "    3. Drop columns with missing values\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    X_train = pd.read_csv(train_path, index_col='Id')\n",
    "    X_test = pd.read_csv(test_path, index_col='Id')\n",
    "    X_train.dropna(axis=0, subset=[target], inplace=True)\n",
    "    \n",
    "    # Concat datasets\n",
    "    X = pd.concat([X_train, X_test], axis=0)\n",
    "    \n",
    "    # Remove rows with missing target, separarte target from features\n",
    "    y = X[target]\n",
    "    X.drop([target], axis=1, inplace=True)\n",
    "    \n",
    "    # Return train and test datasets\n",
    "    return X, y, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ddece8d-84a5-49ce-bbfb-c5f52d272c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 79)\n",
      "(1459, 79)\n",
      "(2919,)\n"
     ]
    }
   ],
   "source": [
    "# Data path and target variable\n",
    "train_path = '../Intro-to-ML/home-data-for-ml-course/train.csv'\n",
    "test_path = '../Intro-to-ML/home-data-for-ml-course/test.csv'\n",
    "target = 'SalePrice'\n",
    "\n",
    "# Load data\n",
    "X, y, X_test = load_data(train_path, test_path, target)\n",
    "\n",
    "# Shape\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c8f9a16-97c8-4e38-8157-1a50275eb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill null values\n",
    "missing_vals = X.isnull().sum()\n",
    "cols_fill_null = missing_vals[missing_vals < 10].index.tolist()\n",
    "X[cols_fill_null] = X[cols_fill_null].fillna(0)\n",
    "\n",
    "# Drop columns with missing values\n",
    "cols_with_missing = [col for col in X.columns if X[col].isnull().any()]\n",
    "X.drop(cols_with_missing, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7c76fdc0-f256-4c5d-9ecd-eccd9394b10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2919, 61)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c51a1b74-4578-484d-b048-9c3ff483b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X.select_dtypes('number').columns\n",
    "cat_features = X.select_dtypes('object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "20cacd13-1058-44ce-b54a-40a0efe5f82a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n",
       "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
       "       'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'Heating',\n",
       "       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
       "       'PavedDrive', 'SaleType', 'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical features\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e63fdd41-721c-4a2e-a89b-41868b6c7218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing numerical features: Series([], dtype: int64)\n",
      "\n",
      "Missing categorical features: Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "missing_val_count_by_column = X[features].isnull().sum()\n",
    "print(f\"Missing numerical features: {missing_val_count_by_column[missing_val_count_by_column > 0]}\")\n",
    "\n",
    "missing_val_count_by_column = X[cat_features].isnull().sum()\n",
    "print(f\"\\nMissing categorical features: {missing_val_count_by_column[missing_val_count_by_column > 0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "096b57dc-29dc-462d-829f-0d2cc84a01c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns that will be one-hot encoded: ['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'ExterQual', 'ExterCond', 'Foundation', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'PavedDrive', 'SaleCondition']\n",
      "\n",
      "Categorical columns that will be dropped from the dataset: ['Exterior1st', 'SaleType', 'Neighborhood', 'Exterior2nd']\n"
     ]
    }
   ],
   "source": [
    "# Columns that will be one-hot encoded\n",
    "low_cardinality_cols = [col for col in cat_features if X[col].nunique() < 10]\n",
    "\n",
    "# Columns that will be dropped from the dataset\n",
    "high_cardinality_cols = list(set(cat_features) - set(low_cardinality_cols))\n",
    "\n",
    "print('Categorical columns that will be one-hot encoded:', low_cardinality_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', high_cardinality_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b19e784a-51bf-448b-96ec-6acc7b624fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding\n",
    "X.drop(high_cardinality_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee74b083-fdaf-4097-aca2-4a7599b38ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categorical columns to string datatypes\n",
    "X[low_cardinality_cols] = X[low_cardinality_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2be625f-ce62-435e-bc87-efd70ffdb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OH_encoding(data):\n",
    "    # Use as many lines of code as you need!\n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(data[low_cardinality_cols]))\n",
    "\n",
    "    # One-Hot encoding removed index; put it back\n",
    "    OH_cols_train.index = data.index\n",
    "\n",
    "    # Remove categorical columns (will replace with one-hot encoding)\n",
    "    num_X_train = data.drop(low_cardinality_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical features\n",
    "    X = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef2e4f0a-2929-4a88-b889-b5ab09a7efbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 160)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform One-Hot Encoding\n",
    "X = OH_encoding(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b761042-0f94-4185-84f7-c82f8085b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat target variable\n",
    "X = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Split dataFrame df back to train and test set\n",
    "dtrain = X[X['SalePrice'].notna()]\n",
    "dtest = X[X['SalePrice'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bc97953f-cf56-48b8-9014-29777e238bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 161)\n",
      "(1459, 161)\n"
     ]
    }
   ],
   "source": [
    "print(dtrain.shape)\n",
    "print(dtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f7b734b9-02e5-40a0-bd12-a58f8d2d3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dtrain['SalePrice']\n",
    "X = dtrain.drop('SalePrice', axis=1)\n",
    "\n",
    "test = dtest.drop('SalePrice', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab3a7a77-1cbd-4f12-91a6-d933fc05c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgustine\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\mgustine\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Fit model to the training set\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Generate predictions\n",
    "preds_test = model.predict(test)\n",
    "\n",
    "# Save predictions in the format used for competition scoring\n",
    "output = pd.DataFrame({'Id': X_test.index,\n",
    "                       'SalePrice': preds_test})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfc68d8b-0e01-434c-95d8-efc4da4cc807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>127045.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>155456.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>173272.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>181311.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>200091.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>85464.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>84751.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>159820.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>112961.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>225171.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  SalePrice\n",
       "0     1461  127045.50\n",
       "1     1462  155456.25\n",
       "2     1463  173272.20\n",
       "3     1464  181311.40\n",
       "4     1465  200091.56\n",
       "...    ...        ...\n",
       "1454  2915   85464.50\n",
       "1455  2916   84751.11\n",
       "1456  2917  159820.87\n",
       "1457  2918  112961.00\n",
       "1458  2919  225171.54\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa41b9-8414-4d48-9f77-a3ed1ac21908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
